{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1\n",
    "\n",
    "**Name:** -- Diana Zepeda Tatengo --\n",
    "\n",
    "**e-mail:** -- diana.zepeda6085@alumnos.udg.mx --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theory on the Gradient Descent algorithm\n",
    "Gradient descent is an optimization algorithm is used to find the minimun of a function using the negative gradient by iteratively moving in the direction of the steepest descent.\n",
    "It updates parameters using the rule:\n",
    "$$\n",
    "w_{t+1} = w_t - n_t * ∇f(w_t)\n",
    "$$\n",
    "where $w_{t+1}$ represents the parameters, $n_t$ is the learning rate, and $∇f(w_t)$ is the gradient of the cost function. \n",
    "The process continues until convergence, which is determined by a stopping criterion such as a small gradient magnitude or a predefined number of iterations.\n",
    "## What is the learning rate?\n",
    "The learning rate $n$ is the size of the steps that are taken to reach the minimum. \n",
    "* A **high** learning rate may cause the algorithm to overshoot the minimum, leading to **divergence**.\n",
    "* A **low** learning rate improves precision but may result in slow **convergence**, requiring more iterations and potentially reducing efficiency.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Himmelblau's function\n",
    "def f_himmelblaus(x, y):\n",
    "    return (x**2 + y - 11) ** 2 + (x + y ** 2 - 7) ** 2 \n",
    "    \n",
    "def dfdx(x, y):\n",
    "    return 4*x**3 + 4*x*y - 42*x + 2*y**2 - 14\n",
    "\n",
    "def dfdy(x, y):\n",
    "    return -26*y + 2*x**2 - 22 + 4*y**3 + 4*x*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run gradient descent algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hw1_mcap",
   "language": "python",
   "name": "hw1_mcap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
